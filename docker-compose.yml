version: '3.8'

services:
  ollama-unsloth:
    build: .
    container_name: ollama-unsloth-training
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_MODELS=/workspace/models/ollama
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_GPU_OVERHEAD=536870912  # 512MB reserved (12GB用に削減)
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256,expandable_segments:True
      - TRANSFORMERS_CACHE=/workspace/models/cache
      - HF_HOME=/workspace/models/huggingface
      - VRAM_LIMIT=12  # 12GB VRAM明示
    volumes:
      - ./data:/workspace/data
      - ./models:/workspace/models
      - ./scripts:/workspace/scripts
      - ./notebooks:/workspace/notebooks
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
      - "8888:8888"
    shm_size: '8gb'  # 12GBの2/3に設定
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 24g  # システムRAM上限

volumes:
  ollama-data: